# Deformable-DETR/main.py 
main(args):

    # Deformable-DETR/models/deformable_detr.py
    model, criterion, postprocessors = build_model(args)        
        build(args):
        
            # Deformable-DETR/models/backbone.py 
            backbone = build_backbone(args)
                position_embedding = build_position_encoding(args)                    
                    position_embedding = PositionEmbeddingSine(N_steps, normalize=True) # '--position_embedding', default='sine'
                        num_pos_feats = 64
                        temperature = 10000
                        normalize = none
                        not_mask = ~mask 
                        scale = 2 * math.pi
                        y_embed = not_mask.cumsum(1, dtype=torch.float32) # row
                        x_embed = not_mask.cumsum(2, dtype=torch.float32) # col
                        
                        # normalize
                        eps = 1e-6
                        y_embed = (y_embed - 0.5) / (y_embed[:, -1:, :] + eps) * self.scale
                        x_embed = (x_embed - 0.5) / (x_embed[:, :, -1:] + eps) * self.scale
                        
                        # dimention
                        dim_t = torch.arange(64, dtype=torch.float32, device=x.device)
                        dim_t = 10000 ** (2 * ([0:63] // 2) / 64) # 10000**[1/64:1]
                        
                        pos_x = x_embed[:, :, :, None] / dim_t # [0:1000]
                        pos_y = y_embed[:, :, :, None] / dim_t 
                        
                        # 偶数sin、奇数cos
                        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)
                        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)
                        
                        # pos
                        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)

                        
                backbone = Backbone(args.backbone, train_backbone, return_interm_layers, args.dilation)
                    self.body = IntermediateLayerGetter(backbone, return_layers=return_layers) # return_layers = {"layer2": "0", "layer3": "1", "layer4": "2"}
                    xs = self.body(tensor_list.tensors)
                    out[name] = NestedTensor(x, mask)
                
                model = Joiner(backbone, position_embedding)
                    # Backbone
                    xs = Backbone(tensor_list)  
                    for name, x in sorted(xs.items()):
                        out.append(x)
                        
                    # position_embedding
                    for x in out:
                        pos.append(position_embedding(x).to(x.tensors.dtype))
                        
                    return out, pos
                    
            # Deformable-DETR/models/deformable_transformer.py
            transformer = build_deforamble_transformer(args)
                d_model=256, 
                dim_feedforward=1024, 
                dropout=0.1,
                activation="relu", 
                num_feature_levels=4, 
                nhead=8,
                enc_n_points=4,
                dec_n_points=4,  
                num_encoder_layers=6, 
                
                num_decoder_layers=6, 
                return_intermediate_dec=False,
                two_stage=False, 
                two_stage_num_proposals=300
                
                encoder_layer = DeformableTransformerEncoderLayer(d_model, dim_feedforward, dropout, activation, num_feature_levels, nhead, enc_n_points)
                    d_model=256, 
                    d_ffn=1024,
                    dropout=0.1, 
                    activation="relu",
                    n_levels=4, 
                    n_heads=8, 
                    n_points=4
                    
                    self.reference_points = nn.Linear(d_model, 2) # (256, 2)
                    
                    # self_attention
                    # Deformable-DETR/models/ops/modules/ms_deform_attn.py
                    src2 = self.MSDeformAttn(self.with_pos_embed(src, pos), reference_points, src, spatial_shapes, level_start_index, padding_mask)
                                            
                        N, Len_q, _ = query.shape
                        N, Len_in, _ = input_flatten.shape
                        
                        # value
                        value = self.value_proj_Linear(input_flatten)
                        
                        # sampling_offsets　(query.shape[0], query.shape[1], 8, 4, 4, 2)
                        sampling_offsets = self.sampling_offsets_Linear(query).view(N, Len_q, self.n_heads, self.n_levels, self.n_points, 2)
                        
                        # attention_weights　(query.shape[0], query.shape[1], 8, 4*4)
                        attention_weights = self.attention_weights_Linear(query).view(N, Len_q, self.n_heads, self.n_levels * self.n_points)
                        # 　(query.shape[0], query.shape[1], 8, 4, 4)
                        attention_weights = F.softmax(attention_weights, -1).view(N, Len_q, self.n_heads, self.n_levels, self.n_points)
                        
                        sampling_locations = reference_points[:, :, None, :, None, :2] + sampling_offsets / self.n_points * reference_points[:, :, None, :, None, 2:] * 0.5
                        
                        # Deformable-DETR/models/ops/functions/ms_deform_attn_func.py
                        output = MSDeformAttnFunction.apply(value, input_spatial_shapes, input_level_start_index, sampling_locations, attention_weights, self.im2col_step)
                  
                        output = self.output_proj_Linear(output)
                        
                    src = src + self.dropout1(src2)
                    src = self.norm1(src)
                    
                    # ffn
                    src2 = self.linear2(self.dropout2(self.activation(self.linear1(src))))
                    src = src + self.dropout3(src2)
                    src = self.norm2(src)
                
                # Deformable-DETR/models/deformable_transformer.py
                self.encoder = DeformableTransformerEncoder(encoder_layer, num_encoder_layers)
                    output = src
                    reference_points = self.get_reference_points(spatial_shapes, valid_ratios, device=src.device)
                    
                    for _, layer in enumerate(self.layers): # num_encoder_layers=6
                        output = encoder_layer(output, pos, reference_points, spatial_shapes, level_start_index, padding_mask)

                    return output
                    
                    
                # Deformable-DETR/models/deformable_transformer.py (256, 1024, 0.1, 'relu', 4, 8, 4)
                decoder_layer = DeformableTransformerDecoderLayer(d_model, dim_feedforward, dropout, activation, num_feature_levels, nhead, dec_n_points)
                
                
                self.decoder = DeformableTransformerDecoder(decoder_layer, num_decoder_layers, return_intermediate_dec)
                
                self.level_embed = nn.Parameter(torch.Tensor(num_feature_levels, d_model))
            
            
            
            
            model = DeformableDETR(
                backbone,
                transformer,
                num_classes=num_classes,
                num_queries=args.num_queries,
                num_feature_levels=args.num_feature_levels,
                aux_loss=args.aux_loss,
                with_box_refine=args.with_box_refine,
                two_stage=args.two_stage,
            )
            
            model = DETRsegm(model, freeze_detr=(args.frozen_weights is not None))
            
            matcher = build_matcher(args)
            
            criterion = SetCriterion(num_classes, matcher, weight_dict, losses, focal_alpha=args.focal_alpha)
            
            postprocessors['segm'] = PostProcessSegm()            
            postprocessors["panoptic"] = PostProcessPanoptic(is_thing_map, threshold=0.85)
            
            return model, criterion, postprocessors
            
    
    # dataset
    dataset_train = build_dataset(image_set='train', args=args)
    dataset_val = build_dataset(image_set='val', args=args)
    
    # sampler
    sampler_train = samplers.NodeDistributedSampler(dataset_train)
    sampler_val = samplers.NodeDistributedSampler(dataset_val, shuffle=False)
    
    # batch
    batch_sampler_train = torch.utils.data.BatchSampler(sampler_train, args.batch_size, drop_last=True)
    
    # data_loader
    data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train, collate_fn=utils.collate_fn, num_workers=args.num_workers, pin_memory=True)
    data_loader_val = DataLoader(dataset_val, args.batch_size, sampler=sampler_val, drop_last=False, collate_fn=utils.collate_fn, num_workers=args.num_workers, pin_memory=True)
    
    # optimizer
    optimizer = torch.optim.SGD(param_dicts, lr=args.lr, momentum=0.9, weight_decay=args.weight_decay)
    
    # lr_scheduler
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_drop)
    
    # checkpoint
    checkpoint = torch.load(args.frozen_weights, map_location='cpu')
    model_without_ddp.detr.load_state_dict(checkpoint['model'])
    
    # optimizer load
    optimizer.load_state_dict(checkpoint['optimizer'])
    
    # lr_scheduler load
    lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])
    
    # evaluate
    if eval:
        test_stats, coco_evaluator = evaluate(model, criterion, postprocessors, data_loader_val, base_ds, device, args.output_dir)
        utils.save_on_master(coco_evaluator.coco_eval["bbox"].eval, output_dir / "eval.pth")
        
    # training
    for epoch in range(args.start_epoch, args.epochs):
        # train_one_epoch
        train_stats = train_one_epoch(model, criterion, data_loader_train, optimizer, device, epoch, args.clip_max_norm)
        
        # add
        if (epoch + 1) % args.lr_drop == 0 or (epoch + 1) % 5 == 0:
                checkpoint_paths.append(output_dir / f'checkpoint{epoch:04}.pth')
                
        # save
        for checkpoint_path in checkpoint_paths:
            utils.save_on_master({
                                'model': model_without_ddp.state_dict(),
                                'optimizer': optimizer.state_dict(),
                                'lr_scheduler': lr_scheduler.state_dict(),
                                'epoch': epoch,
                                'args': args,
                            }, checkpoint_path)
        
        # evaluate
        test_stats, coco_evaluator = evaluate(model, criterion, postprocessors, data_loader_val, base_ds, device, args.output_dir)
        
        # log
        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},**{f'test_{k}': v for k, v in test_stats.items()},'epoch': epoch,'n_parameters': n_parameters}
    


# ------------------------------------------------------------------------------------------------------------------------------------------
# Deformable-DETR/main.py 
    parser.add_argument('--lr', default=2e-4, type=float)
    parser.add_argument('--lr_backbone_names', default=["backbone.0"], type=str, nargs='+')
    parser.add_argument('--lr_backbone', default=2e-5, type=float)
    parser.add_argument('--lr_linear_proj_names', default=['reference_points', 'sampling_offsets'], type=str, nargs='+')
    parser.add_argument('--lr_linear_proj_mult', default=0.1, type=float)
    parser.add_argument('--batch_size', default=2, type=int)
    parser.add_argument('--weight_decay', default=1e-4, type=float)
    parser.add_argument('--epochs', default=50, type=int)
    parser.add_argument('--lr_drop', default=40, type=int)
    parser.add_argument('--lr_drop_epochs', default=None, type=int, nargs='+')
    parser.add_argument('--clip_max_norm', default=0.1, type=float, help='gradient clipping max norm')


    parser.add_argument('--sgd', action='store_true')

    # Variants of Deformable DETR
    parser.add_argument('--with_box_refine', default=False, action='store_true')
    parser.add_argument('--two_stage', default=False, action='store_true')

    # Model parameters
    parser.add_argument('--frozen_weights', type=str, default=None, help="Path to the pretrained model. If set, only the mask head will be trained")

    # * Backbone
    parser.add_argument('--backbone', default='resnet50', type=str, help="Name of the convolutional backbone to use")
    parser.add_argument('--dilation', action='store_true', help="If true, we replace stride with dilation in the last convolutional block (DC5)")
    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'), help="Type of positional embedding to use on top of the image features")
    parser.add_argument('--position_embedding_scale', default=2 * np.pi, type=float, help="position / size * scale")
    parser.add_argument('--num_feature_levels', default=4, type=int, help='number of feature levels')

    # * Transformer
    parser.add_argument('--enc_layers', default=6, type=int, help="Number of encoding layers in the transformer")
    parser.add_argument('--dec_layers', default=6, type=int, help="Number of decoding layers in the transformer")
    parser.add_argument('--dim_feedforward', default=1024, type=int, help="Intermediate size of the feedforward layers in the transformer blocks")
    parser.add_argument('--hidden_dim', default=256, type=int, help="Size of the embeddings (dimension of the transformer)")
    parser.add_argument('--dropout', default=0.1, type=float, help="Dropout applied in the transformer")
    parser.add_argument('--nheads', default=8, type=int,help="Number of attention heads inside the transformer's attentions")
    parser.add_argument('--num_queries', default=300, type=int, help="Number of query slots")
    parser.add_argument('--dec_n_points', default=4, type=int)
    parser.add_argument('--enc_n_points', default=4, type=int)

    # * Segmentation
    parser.add_argument('--masks', action='store_true', help="Train segmentation head if the flag is provided")

    # Loss
    parser.add_argument('--no_aux_loss', dest='aux_loss', action='store_false', help="Disables auxiliary decoding losses (loss at each layer)")

    # * Matcher
    parser.add_argument('--set_cost_class', default=2, type=float, help="Class coefficient in the matching cost")
    parser.add_argument('--set_cost_bbox', default=5, type=float, help="L1 box coefficient in the matching cost")
    parser.add_argument('--set_cost_giou', default=2, type=float, help="giou box coefficient in the matching cost")

    # * Loss coefficients
    parser.add_argument('--mask_loss_coef', default=1, type=float)
    parser.add_argument('--dice_loss_coef', default=1, type=float)
    parser.add_argument('--cls_loss_coef', default=2, type=float)
    parser.add_argument('--bbox_loss_coef', default=5, type=float)
    parser.add_argument('--giou_loss_coef', default=2, type=float)
    parser.add_argument('--focal_alpha', default=0.25, type=float)

    # dataset parameters
    parser.add_argument('--dataset_file', default='coco')
    parser.add_argument('--coco_path', default='./data/coco', type=str)
    parser.add_argument('--coco_panoptic_path', type=str)
    parser.add_argument('--remove_difficult', action='store_true')

    parser.add_argument('--output_dir', default='',help='path where to save, empty for no saving')
    parser.add_argument('--device', default='cuda', help='device to use for training / testing')
    parser.add_argument('--seed', default=42, type=int)
    parser.add_argument('--resume', default='', help='resume from checkpoint')
    parser.add_argument('--start_epoch', default=0, type=int, metavar='N', help='start epoch')
    parser.add_argument('--eval', action='store_true')
    parser.add_argument('--num_workers', default=2, type=int)
    parser.add_argument('--cache_mode', default=False, action='store_true', help='whether to cache images on memory')

# ------------------------------------------------------------------------------------------------------------------------------------------

# Deformable-DETR/tools/launch.py

# Optional arguments for the launch helper
    parser.add_argument("--nnodes", type=int, default=1,
                        help="The number of nodes to use for distributed "
                             "training")
    parser.add_argument("--node_rank", type=int, default=0,
                        help="The rank of the node for multi-node distributed "
                             "training")
    parser.add_argument("--nproc_per_node", type=int, default=1,
                        help="The number of processes to launch on each node, "
                             "for GPU training, this is recommended to be set "
                             "to the number of GPUs in your system so that "
                             "each process can be bound to a single GPU.")
    parser.add_argument("--master_addr", default="127.0.0.1", type=str,
                        help="Master node (rank 0)'s address, should be either "
                             "the IP address or the hostname of node 0, for "
                             "single node multi-proc training, the "
                             "--master_addr can simply be 127.0.0.1")
    parser.add_argument("--master_port", default=29500, type=int,
                        help="Master node (rank 0)'s free port that needs to "
                             "be used for communciation during distributed "
                             "training")

    # positional
    parser.add_argument("training_script", type=str,
                        help="The full path to the single GPU training "
                             "program/script to be launched in parallel, "
                             "followed by all the arguments for the "
                             "training script")

    # rest from the training program
    parser.add_argument('training_script_args', nargs=REMAINDER)
    
    
    for local_rank in range(0, args.nproc_per_node):
        # each process's rank
        dist_rank = args.nproc_per_node * args.node_rank + local_rank
        current_env["RANK"] = str(dist_rank)
        current_env["LOCAL_RANK"] = str(local_rank)

        cmd = [args.training_script] + args.training_script_args

        process = subprocess.Popen(cmd, env=current_env)
        processes.append(process)

    for process in processes:
        process.wait()
        if process.returncode != 0:
            raise subprocess.CalledProcessError(returncode=process.returncode,
                                                cmd=process.args)



# ----------------------------------------------------------------------------------------------------------------------

# Deformable-DETR/tools/run_dist_launch.sh
set -x

GPUS=$1
RUN_COMMAND=${@:2}
if [ $GPUS -lt 8 ]; then
    GPUS_PER_NODE=${GPUS_PER_NODE:-$GPUS}
else
    GPUS_PER_NODE=${GPUS_PER_NODE:-8}
fi
MASTER_ADDR=${MASTER_ADDR:-"127.0.0.1"}
MASTER_PORT=${MASTER_PORT:-"29500"}
NODE_RANK=${NODE_RANK:-0}

let "NNODES=GPUS/GPUS_PER_NODE"

python ./tools/launch.py \
    --nnodes ${NNODES} \
    --node_rank ${NODE_RANK} \
    --master_addr ${MASTER_ADDR} \
    --master_port ${MASTER_PORT} \
    --nproc_per_node ${GPUS_PER_NODE} \
    ${RUN_COMMAND}
    
# ----------------------------------------------------------------------------------------------------------------------
# configs/r50_deformable_detr.sh
set -x

EXP_DIR=exps/r50_deformable_detr
PY_ARGS=${@:1}

python -u main.py \
    --output_dir ${EXP_DIR} \
    ${PY_ARGS}
